{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilfunk/Fundamentals-of-Accelerated-Data-Science-with-RAPIDS/blob/main/Copy_of_ProToken_1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Dreams1de/ProToken/raw/main/fig1.png\" height=\"200\" align=\"middle\" style=\"height:240px\">\n",
        "\n",
        "##ProToken 1.0: Compact and Informative Encoding of Protein 3D Structures\n",
        "\n",
        "Easy to use protein (complex) structure encoding and decoding using ProToken. For more details, see <a href=\"#Instructions\">bottom</a> of the notebook, checkout the [ProToken-1.0 Model](https://drive.google.com/file/d/1z2X_Ly-HXpDryqJIGtnOCuddQi_eIoHS/view?usp=drive_link), [ProToken-1.0 Code Book](https://drive.google.com/file/d/1PpK8iKcD2OoQvcDs2bnsA9dJ97GnhrNq/view?usp=drive_link) and read our manuscript.\n",
        "\n",
        "[Xiaohan Lin, Zhenyu Chen, Yanheng Li, Xingyu Lu, Chuanliu Fan, Ziqiang Cao, Shihao Feng, Yi Qin Gao, Jun Zhang. ProTokens: A Machine-Learned Language for Compact and Informative Encoding of Protein 3D Structures.\n",
        "*biorxiv*, 2023](https://www.biorxiv.org/content/10.1101/2023.11.27.568722v2.abstract)\n",
        "\n",
        "Report issues or bugs, please contact: fengsh@cpl.ac.cn or jzhang@cpl.ac.cn. For prompt reply, It is recommended to include #ProToken# in your mail title.\n",
        "\n",
        "Thanks for [Sergey Ovchinnikov's ColabFold Colab Notebook](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2.ipynb#scrollTo=kOblAo-xetgx) for reference."
      ],
      "metadata": {
        "id": "z5x4C_yt8-9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Copyright 2024 Changping Laboratory & Peking University. All Rights Reserved.\n",
        "# Licensed under the Apache License, Version 2.0 (the “License”);\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an “AS IS” BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "vxQ7xhQQCBEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Input protein structure(s), then hit `Runtime` -> `Run all`\n",
        "\n",
        "# download the package from google drive and prepare the libraries\n",
        "import os\n",
        "if not os.path.exists('/content/ProToken-1.0'):\n",
        "  !gdown --id '1z2X_Ly-HXpDryqJIGtnOCuddQi_eIoHS'\n",
        "  !gdown --id '1PpK8iKcD2OoQvcDs2bnsA9dJ97GnhrNq'\n",
        "  !tar -xJf '/content/ProToken-1.0.tar.xz'\n",
        "  !pip install biopython -q\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "jobname = 'test' #@param {type:\"string\"}\n",
        "\n",
        "user_mode = \"single_example\" #@param [\"single_example\", \"multimer_example\",\"custom_example\"]\n",
        "#@markdown - `single_example` = using example in /content/ProToken-1.0/examples/single (see [notes](#single_example)).\n",
        "#@markdown - `multimer_example` = using example in /content/ProToken-1.0/examples/multimer (see [notes](#multimer_example)).\n",
        "#@markdown - `custom_example` = upload and use own protein structure(s) (PDB format **only contains lines start with 'ATOM'**. see [notes](#custom_example)).\n",
        "\n",
        "task_mode = \"single\" #@param [\"single\", \"multi\"]\n",
        "#@markdown - `single` = support one single-chain pdb file under the input pdb file directory.\n",
        "#@markdown - `multi` = support more than one single-chain pdb files under the input pdb file directory.\n",
        "\n",
        "# check if directory with jobname exists\n",
        "def check(folder):\n",
        "  if os.path.exists(folder):\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "if not check(jobname):\n",
        "  n = 0\n",
        "  while not check(f\"{jobname}_{n}\"): n += 1\n",
        "  jobname = f\"{jobname}_{n}\"\n",
        "\n",
        "# make directory to save results\n",
        "os.makedirs(jobname, exist_ok=True)\n",
        "\n",
        "if user_mode == 'custom_example':\n",
        "  input_pdb_dir = os.path.join(jobname,f\"input_pdbs\")\n",
        "  os.makedirs(input_pdb_dir, exist_ok=True)\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    os.rename(fn,os.path.join(input_pdb_dir,fn))\n",
        "  pdb_input_dir = input_pdb_dir\n",
        "  if task_mode == 'multi':\n",
        "    assert len(list(uploaded.keys())) > 1, 'task_mode should be set to single!~'\n",
        "  if task_mode == 'single':\n",
        "    assert len(list(uploaded.keys())) == 1, 'task_mode should be set to multi!~'\n",
        "\n",
        "if user_mode == 'multimer_example':\n",
        "  assert task_mode == 'multi', 'task_mode should be set to multi!~'\n",
        "  pdb_input_dir = '/content/ProToken-1.0/examples/multimer'\n",
        "if user_mode == 'single_example':\n",
        "  assert task_mode == 'single', 'task_mode should be set to single!~'\n",
        "  pdb_input_dir = '/content/ProToken-1.0/examples/single'\n",
        "\n",
        "pdb_saving_path = os.path.join(jobname, 'reconstructed_protein.pdb')\n",
        "code_saving_path = os.path.join(jobname, 'protoken_index.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "axweXskzr3DN",
        "outputId": "9060835b-ed6d-44f9-cf7f-ad9732429f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1z2X_Ly-HXpDryqJIGtnOCuddQi_eIoHS\n",
            "From (redirected): https://drive.google.com/uc?id=1z2X_Ly-HXpDryqJIGtnOCuddQi_eIoHS&confirm=t&uuid=436d8c47-c45b-41ee-9a2c-4230a28ebb1e\n",
            "To: /content/ProToken-1.0.tar.xz\n",
            "100% 361M/361M [00:07<00:00, 51.2MB/s]\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Import the libraries\n",
        "import os, jax\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "protoken_base_dir = '/content/ProToken-1.0'\n",
        "import sys\n",
        "sys.path.append(protoken_base_dir)\n",
        "from data_process.preprocess import save_pdb_from_aux, protoken_encoder_preprocess, protoken_decoder_preprocess, init_protoken_model\n",
        "from data_process.preprocess import protoken_encoder_input_features, protoken_decoder_input_features"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iEM2M3CHbbeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Prepare the encoder's inputs\n",
        "\n",
        "encoder_inputs, encoder_aux, seq_len = protoken_encoder_preprocess(pdb_input_dir, task_mode=task_mode)\n",
        "for k, v in zip(protoken_encoder_input_features, encoder_inputs):\n",
        "    print(k, v.shape)\n",
        "\n",
        "if task_mode == 'multi':\n",
        "  # multimer auxiliary information\n",
        "  print('\\nHere is the brief information for multi-chain complexes:')\n",
        "  for k, v in encoder_aux['chain_length_info'].items():\n",
        "    print(f'chain {k}: ', v)"
      ],
      "metadata": {
        "id": "mBWezD8f8wZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "2bd0712f-680a-4aec-cb45-83ec24eafb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 pdb files in the input directory.\n",
            "WARNING: The input pdb files should be single-chain pdb files.\n",
            "seq_mask (512,)\n",
            "residue_index (512,)\n",
            "backbone_atom_masks (512, 37)\n",
            "backbone_atom_positions (512, 37, 3)\n",
            "ca_pos (512, 3)\n",
            "backbone_affine_tensor (512, 7)\n",
            "torsion_angles_sin_cos (512, 6)\n",
            "torsion_angles_mask (512, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Warm up the encoder and decoder\n",
        "\n",
        "#@markdown We have 3 models for different total sequence lengths ranging from `0-512`, `512-1024`, `1024-2048`.\n",
        "\n",
        "#@markdown You can choose the model based on the sequence length of your protein. Currently, T4 GPU supports the sequence length up to 1024.\n",
        "\n",
        "#@markdown Once the total sequence length is beyond the current model's length coverage, you have to `reinitialize the model`.\n",
        "\n",
        "#@markdown Have fun!\n",
        "\n",
        "model = init_protoken_model(seq_len, '/content/ProToken-1.0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "CE0riO9jcb2r",
        "outputId": "078804f4-ece4-4dc7-9253-d256d82ddf3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU, will use GPU for prediction\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_113922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_195207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Encode the protein structure and get the ProToken Index\n",
        "\n",
        "encoder_results = model.encoder(*encoder_inputs)\n",
        "\n",
        "if task_mode == 'multi':\n",
        "  protoken_index_ = np.asarray([encoder_results[\"protoken_index\"][p] for p in range(encoder_aux['seq_mask'].shape[0]) \\\n",
        "                                if encoder_aux['seq_mask'][p]])\n",
        "  protoken_index_multimer = [protoken_index_[v['start_idx']:v['start_idx']+v['seq_len']] for k, v in encoder_aux['chain_length_info'].items()]\n",
        "  for k in encoder_aux['chain_length_info'].keys():\n",
        "      print('PDB ID: ', encoder_aux['chain_length_info'][k]['pdb_name'])\n",
        "      print(f'Chain Length: ', encoder_aux['chain_length_info'][k]['seq_len'])\n",
        "      print(f'ProToken Index: {protoken_index_multimer[k].shape}\\n{protoken_index_multimer[k]}')\n",
        "      encoder_aux['chain_length_info'][k]['protoken_index'] = protoken_index_multimer[k]\n",
        "  with open(code_saving_path, 'wb') as f:\n",
        "      pkl.dump(encoder_aux['chain_length_info'], f)\n",
        "else:\n",
        "  protoken_index = np.asarray([encoder_results[\"protoken_index\"][p] for p in range(encoder_aux['seq_mask'].shape[0]) \\\n",
        "                                if encoder_aux['seq_mask'][p]])\n",
        "  print(f'ProToken Index: {protoken_index.shape}\\n{protoken_index}')\n",
        "  with open(code_saving_path, 'wb') as f:\n",
        "      pkl.dump(protoken_index, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "EfF0it8_cb9P",
        "outputId": "28285d18-1431-4acb-8526-f192e45a040e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ProToken Index: (193,)\n",
            "[258 384 416 294 324 454 324 227 127 104 342 100 373 381  92 215 487 403\n",
            "  92 250 509 324 240 177 256 472 384  74 228 471  24 241 329 202 369 132\n",
            " 458 487  47 333 151 267 231 483 133  51  28 132  32   0 362  78 493 220\n",
            "  24  12 196 364 337 210 358 439 367 161 293 216 450 110 106 266 257 473\n",
            " 495 291  46 503  92 328 214  48 384 360 146 266 476  50 297 185 241  50\n",
            "  34 362 241 485 163 237 304  27 419 299  72  42 293 329 430  76 315 152\n",
            " 481 268 315 123 361  59 194 262 372 248 130 268 425 109 256 118 386 264\n",
            " 393 305 347 190 411 403 106 407 446  14  38 487 161 342 190 254  42 334\n",
            "  49 125 187 466 143 457 324 439 109 161 456 163  30 161 415 440 151 170\n",
            " 291 395 274  42 457 246  25  42 224 315 442 471 349 303 442 202 451 261\n",
            "  38 272 165 230 466 168 434 247 450 411  52  95 264]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Prepare the decoder's inputs\n",
        "\n",
        "if task_mode == 'multi':\n",
        "  # Multimer ProToken decoder's inputs should be a list of ProToken index and ProToken index should be in np.ndarray format.\n",
        "  decoder_inputs = protoken_decoder_preprocess(protoken_index_multimer, task_mode=task_mode)\n",
        "  for k, v in zip(protoken_decoder_input_features, decoder_inputs):\n",
        "      print(f'{k}: {v.shape}')\n",
        "else:\n",
        "  # Single chain ProToken decoder's inputs should be a array of ProToken indexes in the np.ndarray format.\n",
        "  decoder_inputs = protoken_decoder_preprocess(protoken_index, task_mode=task_mode)\n",
        "  for k, v in zip(protoken_decoder_input_features, decoder_inputs):\n",
        "      print(f'{k}: {v.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "p-CML9_kccAT",
        "outputId": "558d0de0-f9f0-4d03-8349-e7626fed6055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "protoken_index: (512,)\n",
            "protoken_mask: (512,)\n",
            "residue_index: (512,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. Decode the ProToken Index and get the reconstructed protein structure\n",
        "\n",
        "decoder_results = model.decoder(*decoder_inputs)\n",
        "reconstructed_atom_positions = np.asarray(decoder_results['reconstructed_atom_positions'])"
      ],
      "metadata": {
        "id": "kgfdITJmccC5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. Compare the original and reconstructed protein structures\n",
        "\n",
        "from data_process.preprocess import lddt\n",
        "lDDT = lddt(reconstructed_atom_positions[None, ...][:,:,1,:],\n",
        "            encoder_aux['backbone_atom_positions'][None, ...][:,:,1,:],\n",
        "            encoder_aux['seq_mask'][None,...,None], per_residue=True)[0]\n",
        "print(f\"Average lDDT: {np.mean(lDDT[:np.sum(encoder_aux['seq_mask'])])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVCYBdlAccFO",
        "outputId": "99c258be-2588-4af3-dd79-d693bbc406e2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average lDDT: 0.9680577494332036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8. Save the reconstructed protein structure\n",
        "\n",
        "partial_aux = {\"aatype\": encoder_aux[\"aatype\"].astype(np.int32),\n",
        "               \"residue_index\": decoder_inputs[-1].astype(np.int32)+1,\n",
        "               \"atom_positions\": reconstructed_atom_positions.astype(np.float32),\n",
        "               \"atom_mask\": encoder_aux[\"backbone_atom_masks\"].astype(np.float32),\n",
        "               \"plddt\": lDDT.astype(np.float32)}\n",
        "save_pdb_from_aux(partial_aux, pdb_saving_path)\n",
        "\n",
        "# if you want to save the protein without encoder_aux,\n",
        "# use the following code to save the protein\n",
        "# aatype_all_gly = np.asarray(decoder_inputs[1]).astype(np.int32)*7\n",
        "# backbone_atom_mask = np.repeat(np.asarray([1,1,1,0,1]+[0]*32)[None,...], aatype_all_gly.shape[0], axis=0).astype(np.float32)*decoder_inputs[1][..., None]\n",
        "# plddt = np.ones_like(aatype_all_gly).astype(np.float32)*99.99\n",
        "# partial_aux = {\"aatype\": aatype_all_gly,\n",
        "#                \"residue_index\": decoder_inputs[-1].astype(np.int32)+1,\n",
        "#                \"atom_positions\": reconstructed_atom_positions.astype(np.float32),\n",
        "#                \"atom_mask\": backbone_atom_mask,\n",
        "#                \"plddt\": plddt}\n",
        "# save_pdb_from_aux(partial_aux, pdb_saving_path)"
      ],
      "metadata": {
        "id": "B_waFDimccHk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 9. Conclusion\n",
        "\n",
        "print(f'PDB saved at: {pdb_saving_path}')\n",
        "print(f'ProTokens saved at: {code_saving_path}')\n",
        "print('Average lDDT:', round(np.mean(lDDT[:np.sum(encoder_aux['seq_mask'])]), 3), 'Seq_Len:', seq_len)\n",
        "print(f'Job finished!\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "c6SBj4hoccJq",
        "outputId": "3283820c-e236-420f-a951-3625dcb5dbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDB saved at: test/reconstructed_protein.pdb\n",
            "ProTokens saved at: test/protoken_index.pkl\n",
            "Average lDDT: 0.968 Seq_Len: 193\n",
            "Job finished!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions <a name=\"Instructions\"></a>\n",
        "\n",
        "#### <u>Quick start</u>\n",
        "1. Paste your protein structure(s) in the input field or using the examples provided in the google drive.\n",
        "2. Press \"Runtime\" -> \"Run all\".\n",
        "3. The pipeline consists of 9 steps. The currently running step is indicated by a circle with a stop sign next to it.\n",
        "\n",
        "#### <u>Single-Chain Example</u> <a name=\"single_example\"></a>\n",
        "\n",
        "**Example**: T1024-D1.pdb from [CASP14](https://predictioncenter.org/casp14/index.cgi).\n",
        "\n",
        "This example involves a single-chain protein structure sourced from CASP14, specifically designed to illustrate the model's application on individual protein chains.\n",
        "\n",
        "#### <u>Multimer Example</u> <a name=\"multimer_example\"></a>\n",
        "\n",
        "**Example**: 7W51_A.pdb & 7W51_B.pdb.\n",
        "\n",
        "These multimer examples were released on October 26, 2022, and are available in the [RCSB Protein Data Bank](https://www.rcsb.org/structure/7W51). The files include structures for two separate chains within a multimeric protein.\n",
        "\n",
        "#### <u>Custom Examples</u> <a name=\"custom_example\"></a>\n",
        "\n",
        "Users are encouraged to upload their own PDB files online to test the model. For optimal results, please adhere to the following guidelines:\n",
        "\n",
        "**Important Guidelines:**\n",
        "1. Ensure that each PDB file contains the protein structure of only one chain.\n",
        "2. The PDB file should only contain lines that start with `ATOM`. Lines starting with `HETATM` or other prefixes may adversely affect the model's performance.\n",
        "\n",
        "\n",
        "#### <u>Local Test</u>\n",
        "\n",
        "You can download the model and test it on your local devices through [ProToken-1.0 Model](https://drive.google.com/file/d/1z2X_Ly-HXpDryqJIGtnOCuddQi_eIoHS/view?usp=drive_link).\n",
        "\n",
        "\n",
        "#### <u>ProToken-1.0 Code Book</u>\n",
        "We also release the [ProToken-1.0 Code Book](https://drive.google.com/file/d/1PpK8iKcD2OoQvcDs2bnsA9dJ97GnhrNq/view?usp=drive_link), which contains a 32-dimensional embedding for each code (512 codes in total)."
      ],
      "metadata": {
        "id": "hHsd6GMBmfhC"
      }
    }
  ]
}